{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8553d7f",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-03-18T18:33:22.553678Z",
     "iopub.status.busy": "2024-03-18T18:33:22.553336Z",
     "iopub.status.idle": "2024-03-18T18:33:22.558801Z",
     "shell.execute_reply": "2024-03-18T18:33:22.557925Z"
    },
    "papermill": {
     "duration": 0.018947,
     "end_time": "2024-03-18T18:33:22.561071",
     "exception": false,
     "start_time": "2024-03-18T18:33:22.542124",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# # For example, here's several helpful packages to load\n",
    "\n",
    "# import numpy as np # linear algebra\n",
    "# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# # Input data files are available in the read-only \"../input/\" directory\n",
    "# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac46e963",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T18:33:22.581176Z",
     "iopub.status.busy": "2024-03-18T18:33:22.580829Z",
     "iopub.status.idle": "2024-03-18T18:33:53.846637Z",
     "shell.execute_reply": "2024-03-18T18:33:53.845414Z"
    },
    "papermill": {
     "duration": 31.278557,
     "end_time": "2024-03-18T18:33:53.849318",
     "exception": false,
     "start_time": "2024-03-18T18:33:22.570761",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchview\r\n",
      "  Downloading torchview-0.2.6-py3-none-any.whl.metadata (12 kB)\r\n",
      "Downloading torchview-0.2.6-py3-none-any.whl (25 kB)\r\n",
      "Installing collected packages: torchview\r\n",
      "Successfully installed torchview-0.2.6\r\n",
      "Collecting torchviz\r\n",
      "  Downloading torchviz-0.0.2.tar.gz (4.9 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from torchviz) (2.1.2)\r\n",
      "Requirement already satisfied: graphviz in /opt/conda/lib/python3.10/site-packages (from torchviz) (0.20.1)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->torchviz) (3.13.1)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->torchviz) (4.9.0)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->torchviz) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->torchviz) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->torchviz) (3.1.2)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->torchviz) (2024.2.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->torchviz) (2.1.3)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->torchviz) (1.3.0)\r\n",
      "Building wheels for collected packages: torchviz\r\n",
      "  Building wheel for torchviz (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for torchviz: filename=torchviz-0.0.2-py3-none-any.whl size=4131 sha256=20fb1affe9b34e6fdfdd1a5e05dc1dad5014d387d21ab09d7df8f91b603cc87f\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/4c/97/88/a02973217949e0db0c9f4346d154085f4725f99c4f15a87094\r\n",
      "Successfully built torchviz\r\n",
      "Installing collected packages: torchviz\r\n",
      "Successfully installed torchviz-0.0.2\r\n"
     ]
    }
   ],
   "source": [
    "!pip install torchview\n",
    "!pip install torchviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fea2b51d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T18:33:53.871562Z",
     "iopub.status.busy": "2024-03-18T18:33:53.871186Z",
     "iopub.status.idle": "2024-03-18T18:33:59.120063Z",
     "shell.execute_reply": "2024-03-18T18:33:59.119049Z"
    },
    "papermill": {
     "duration": 5.262993,
     "end_time": "2024-03-18T18:33:59.122532",
     "exception": false,
     "start_time": "2024-03-18T18:33:53.859539",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f27bb811550>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import torch\n",
    "import ctypes\n",
    "import gc\n",
    "libc = ctypes.CDLL(\"libc.so.6\")\n",
    "seed = 42\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a243a8e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T18:33:59.145901Z",
     "iopub.status.busy": "2024-03-18T18:33:59.145405Z",
     "iopub.status.idle": "2024-03-18T18:34:37.682829Z",
     "shell.execute_reply": "2024-03-18T18:34:37.681902Z"
    },
    "papermill": {
     "duration": 38.551627,
     "end_time": "2024-03-18T18:34:37.685468",
     "exception": false,
     "start_time": "2024-03-18T18:33:59.133841",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groups in the HDF5 file:\n",
      "Y\n",
      "jet\n",
      "Dataset shape: (10000, 125, 125, 8)\n",
      "Dataset dtype: float32\n",
      "Dataset shape: (10000, 1)\n",
      "Dataset dtype: float32\n",
      "Dataset attributes:\n"
     ]
    }
   ],
   "source": [
    "# Open the HDF5 file\n",
    "import h5py\n",
    "with h5py.File('/kaggle/input/autoencoders-labelled/Dataset_Specific_labelled.h5', 'r') as file:\n",
    "    # List all the groups in the file\n",
    "    print(\"Groups in the HDF5 file:\")\n",
    "    for group in file:\n",
    "        print(group)\n",
    "\n",
    "    # Get information about a specific dataset\n",
    "    dataset = file['jet']\n",
    "    print(\"Dataset shape:\", dataset.shape)\n",
    "    print(\"Dataset dtype:\", dataset.dtype)\n",
    "    \n",
    "    dataset = file['Y']\n",
    "    print(\"Dataset shape:\", dataset.shape)\n",
    "    print(\"Dataset dtype:\", dataset.dtype)\n",
    "\n",
    "\n",
    "    # Explore attributes of the dataset\n",
    "    print(\"Dataset attributes:\")\n",
    "    for attr_name, attr_value in dataset.attrs.items():\n",
    "        print(f\"{attr_name}: {attr_value}\")\n",
    "\n",
    "    X = np.array(file['jet'][:])\n",
    "    Y = np.array(file['Y'][:])\n",
    "    # Explore more datasets, groups, and attributes as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49dea15f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T18:34:37.708102Z",
     "iopub.status.busy": "2024-03-18T18:34:37.707751Z",
     "iopub.status.idle": "2024-03-18T18:34:37.714504Z",
     "shell.execute_reply": "2024-03-18T18:34:37.713571Z"
    },
    "papermill": {
     "duration": 0.02036,
     "end_time": "2024-03-18T18:34:37.716703",
     "exception": false,
     "start_time": "2024-03-18T18:34:37.696343",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 125, 125, 8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a93035",
   "metadata": {
    "papermill": {
     "duration": 0.010239,
     "end_time": "2024-03-18T18:34:37.738439",
     "exception": false,
     "start_time": "2024-03-18T18:34:37.728200",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef2e24ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T18:34:37.760992Z",
     "iopub.status.busy": "2024-03-18T18:34:37.760637Z",
     "iopub.status.idle": "2024-03-18T18:34:37.773170Z",
     "shell.execute_reply": "2024-03-18T18:34:37.772220Z"
    },
    "papermill": {
     "duration": 0.026222,
     "end_time": "2024-03-18T18:34:37.775270",
     "exception": false,
     "start_time": "2024-03-18T18:34:37.749048",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "def get_2d_sincos_pos_embed(embed_dim, grid_size, cls_token=False):\n",
    "    \"\"\"\n",
    "    grid_size: int of the grid height and width\n",
    "    return:\n",
    "    pos_embed: [grid_size*grid_size, embed_dim] or [1+grid_size*grid_size, embed_dim] (w/ or w/o cls_token)\n",
    "    \"\"\"\n",
    "    grid_h = np.arange(grid_size, dtype=np.float32)\n",
    "    grid_w = np.arange(grid_size, dtype=np.float32)\n",
    "    grid = np.meshgrid(grid_w, grid_h)  # here w goes first\n",
    "    grid = np.stack(grid, axis=0)\n",
    "\n",
    "    grid = grid.reshape([2, 1, grid_size, grid_size])\n",
    "    pos_embed = get_2d_sincos_pos_embed_from_grid(embed_dim, grid)\n",
    "    if cls_token:\n",
    "        pos_embed = np.concatenate([np.zeros([1, embed_dim]), pos_embed], axis=0)\n",
    "    return pos_embed\n",
    "\n",
    "\n",
    "def get_2d_sincos_pos_embed_from_grid(embed_dim, grid):\n",
    "    assert embed_dim % 2 == 0\n",
    "\n",
    "    # use half of dimensions to encode grid_h\n",
    "    emb_h = get_1d_sincos_pos_embed_from_grid(embed_dim // 2, grid[0])  # (H*W, D/2)\n",
    "    emb_w = get_1d_sincos_pos_embed_from_grid(embed_dim // 2, grid[1])  # (H*W, D/2)\n",
    "\n",
    "    emb = np.concatenate([emb_h, emb_w], axis=1) # (H*W, D)\n",
    "    return emb\n",
    "\n",
    "\n",
    "def get_1d_sincos_pos_embed_from_grid(embed_dim, pos):\n",
    "    \"\"\"\n",
    "    embed_dim: output dimension for each position\n",
    "    pos: a list of positions to be encoded: size (M,)\n",
    "    out: (M, D)\n",
    "    \"\"\"\n",
    "    assert embed_dim % 2 == 0\n",
    "    omega = np.arange(embed_dim // 2, dtype='float32')\n",
    "    omega /= embed_dim / 2.\n",
    "    omega = 1. / 10000**omega  # (D/2,)\n",
    "\n",
    "    pos = pos.reshape(-1)  # (M,)\n",
    "    out = np.einsum('m,d->md', pos, omega)  # (M, D/2), outer product\n",
    "\n",
    "    emb_sin = np.sin(out) # (M, D/2)\n",
    "    emb_cos = np.cos(out) # (M, D/2)\n",
    "\n",
    "    emb = np.concatenate([emb_sin, emb_cos], axis=1)  # (M, D)\n",
    "    return emb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "931e19e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T18:34:37.798341Z",
     "iopub.status.busy": "2024-03-18T18:34:37.798038Z",
     "iopub.status.idle": "2024-03-18T18:34:44.266802Z",
     "shell.execute_reply": "2024-03-18T18:34:44.265906Z"
    },
    "papermill": {
     "duration": 6.48354,
     "end_time": "2024-03-18T18:34:44.269432",
     "exception": false,
     "start_time": "2024-03-18T18:34:37.785892",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from timm.models.vision_transformer import PatchEmbed, Block\n",
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from timm.models.vision_transformer import PatchEmbed, Block\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, img_size=224, patch_size=16, in_chans=8,\n",
    "                 embed_dim=1024, depth=24, num_heads=16,\n",
    "                 decoder_embed_dim=512, decoder_depth=8, decoder_num_heads=16,\n",
    "                 mlp_ratio=4., norm_layer=nn.LayerNorm, norm_pix_loss=False):\n",
    "        super().__init__()\n",
    "\n",
    "        # --------------------------------------------------------------------------\n",
    "        # MAE encoder specifics\n",
    "        self.mask_ratio = 0.75\n",
    "        self.patch_embed = PatchEmbed(img_size, patch_size, in_chans, embed_dim)\n",
    "        num_patches = self.patch_embed.num_patches\n",
    "\n",
    "        self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
    "        self.pos_embed = nn.Parameter(torch.zeros(1, num_patches + 1, embed_dim), requires_grad=False)  # fixed sin-cos embedding\n",
    "\n",
    "        self.blocks = nn.ModuleList([\n",
    "            Block(embed_dim, num_heads, mlp_ratio, qkv_bias=True, norm_layer=norm_layer)\n",
    "            for i in range(depth)])\n",
    "        \n",
    "        self.norm = norm_layer(embed_dim)\n",
    "\n",
    "        self.initialize_weights()\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        # initialization\n",
    "        # initialize (and freeze) pos_embed by sin-cos embedding\n",
    "        pos_embed = get_2d_sincos_pos_embed(self.pos_embed.shape[-1], int(self.patch_embed.num_patches**.5), cls_token=True)\n",
    "        self.pos_embed.data.copy_(torch.from_numpy(pos_embed).float().unsqueeze(0))\n",
    "\n",
    "        # initialize patch_embed like nn.Linear (instead of nn.Conv2d)\n",
    "        w = self.patch_embed.proj.weight.data\n",
    "        torch.nn.init.xavier_uniform_(w.view([w.shape[0], -1]))\n",
    "\n",
    "        # timm's trunc_normal_(std=.02) is effectively normal_(std=0.02) as cutoff is too big (2.)\n",
    "        torch.nn.init.normal_(self.cls_token, std=.02)\n",
    "\n",
    "        # initialize nn.Linear and nn.LayerNorm\n",
    "        self.apply(self._init_weights)\n",
    "    \n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            # we use xavier_uniform following official JAX ViT:\n",
    "            torch.nn.init.xavier_uniform_(m.weight)\n",
    "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "            nn.init.constant_(m.weight, 1.0)\n",
    "        \n",
    "    def patchify(self, imgs):\n",
    "        \"\"\"\n",
    "        imgs: (N, 8, H, W)\n",
    "        x: (N, L, patch_size**2 *3)\n",
    "        \"\"\"\n",
    "        p = self.patch_embed.patch_size[0]\n",
    "        assert imgs.shape[2] == imgs.shape[3] and imgs.shape[2] % p == 0\n",
    "\n",
    "        h = w = imgs.shape[2] // p\n",
    "        x = imgs.reshape(shape=(imgs.shape[0], 8, h, p, w, p))\n",
    "        x = torch.einsum('nchpwq->nhwpqc', x)\n",
    "        x = x.reshape(shape=(imgs.shape[0], h * w, p**2 * 8))\n",
    "        return x\n",
    "\n",
    "    def unpatchify(self, x):\n",
    "        \"\"\"\n",
    "        x: (N, L, patch_size**2 *3)\n",
    "        imgs: (N, 8, H, W)\n",
    "        \"\"\"\n",
    "        p = self.patch_embed.patch_size[0]\n",
    "        h = w = int(x.shape[1]**.5)\n",
    "        assert h * w == x.shape[1]\n",
    "        \n",
    "        x = x.reshape(shape=(x.shape[0], h, w, p, p, 8))\n",
    "        x = torch.einsum('nhwpqc->nchpwq', x)\n",
    "        imgs = x.reshape(shape=(x.shape[0], 8, h * p, h * p))\n",
    "        return imgs\n",
    "\n",
    "    def random_masking(self, x, mask_ratio):\n",
    "        \"\"\"\n",
    "        Perform per-sample random masking by per-sample shuffling.\n",
    "        Per-sample shuffling is done by argsort random noise.\n",
    "        x: [N, L, D], sequence\n",
    "        \"\"\"\n",
    "        N, L, D = x.shape  # batch, length, dim\n",
    "        len_keep = int(L * (1 - mask_ratio))\n",
    "        \n",
    "        noise = torch.rand(N, L, device=x.device)  # noise in [0, 1]\n",
    "        \n",
    "        # sort noise for each sample\n",
    "        ids_shuffle = torch.argsort(noise, dim=1)  # ascend: small is keep, large is remove\n",
    "        ids_restore = torch.argsort(ids_shuffle, dim=1)\n",
    "\n",
    "        # keep the first subset\n",
    "        ids_keep = ids_shuffle[:, :len_keep]\n",
    "        x_masked = torch.gather(x, dim=1, index=ids_keep.unsqueeze(-1).repeat(1, 1, D))\n",
    "\n",
    "        # generate the binary mask: 0 is keep, 1 is remove\n",
    "        mask = torch.ones([N, L], device=x.device)\n",
    "        mask[:, :len_keep] = 0\n",
    "        # unshuffle to get the binary mask\n",
    "        mask = torch.gather(mask, dim=1, index=ids_restore)\n",
    "\n",
    "        return x_masked, mask, ids_restore\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        imgs = self.patchify(x)\n",
    "        \n",
    "        # embed patches\n",
    "        x = self.patch_embed(x)\n",
    "\n",
    "        # add pos embed w/o cls token\n",
    "        x = x + self.pos_embed[:, 1:, :]\n",
    "\n",
    "        # masking: length -> length * mask_ratio\n",
    "        x, mask, ids_restore = self.random_masking(x, self.mask_ratio)\n",
    "\n",
    "        # append cls token\n",
    "        cls_token = self.cls_token + self.pos_embed[:, :1, :]\n",
    "        cls_tokens = cls_token.expand(x.shape[0], -1, -1)\n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "\n",
    "        # apply Transformer blocks\n",
    "        for blk in self.blocks:\n",
    "            x = blk(x)\n",
    "        x = self.norm(x)\n",
    "        \n",
    "        \n",
    "        \n",
    "        return x, mask, ids_restore, imgs\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, img_size=224, patch_size=16, in_chans=8,\n",
    "                 embed_dim=1024, depth=24, num_heads=16,\n",
    "                 decoder_embed_dim=512, decoder_depth=8, decoder_num_heads=16,\n",
    "                 mlp_ratio=4., norm_layer=nn.LayerNorm, norm_pix_loss=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_patches = (img_size//patch_size)**2\n",
    "        self.decoder_embed = nn.Linear(embed_dim, decoder_embed_dim, bias=True)\n",
    "\n",
    "        self.mask_token = nn.Parameter(torch.zeros(1, 1, decoder_embed_dim))\n",
    "\n",
    "        self.decoder_pos_embed = nn.Parameter(torch.zeros(1, self.num_patches + 1, decoder_embed_dim), requires_grad=False)  # fixed sin-cos embedding\n",
    "\n",
    "        self.decoder_blocks = nn.ModuleList([\n",
    "            Block(decoder_embed_dim, decoder_num_heads, mlp_ratio, qkv_bias=True, norm_layer=norm_layer)\n",
    "            for i in range(decoder_depth)])\n",
    "\n",
    "        self.decoder_norm = norm_layer(decoder_embed_dim)\n",
    "        self.decoder_pred = nn.Linear(decoder_embed_dim, patch_size**2 * in_chans, bias=True) # decoder to patch\n",
    "        # --------------------------------------------------------------------------\n",
    "\n",
    "        self.norm_pix_loss = norm_pix_loss\n",
    "\n",
    "        self.initialize_weights()\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        # initialization\n",
    "        # initialize (and freeze) pos_embed by sin-cos embedding\n",
    "\n",
    "        decoder_pos_embed = get_2d_sincos_pos_embed(self.decoder_pos_embed.shape[-1], int(self.num_patches**.5), cls_token=True)\n",
    "        self.decoder_pos_embed.data.copy_(torch.from_numpy(decoder_pos_embed).float().unsqueeze(0))\n",
    "\n",
    "        # timm's trunc_normal_(std=.02) is effectively normal_(std=0.02) as cutoff is too big (2.)\n",
    "        torch.nn.init.normal_(self.mask_token, std=.02)\n",
    "\n",
    "        # initialize nn.Linear and nn.LayerNorm\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            # we use xavier_uniform following official JAX ViT:\n",
    "            torch.nn.init.xavier_uniform_(m.weight)\n",
    "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "            nn.init.constant_(m.weight, 1.0)\n",
    "\n",
    "    def patchify(self, imgs):\n",
    "        \"\"\"\n",
    "        imgs: (N, 8, H, W)\n",
    "        x: (N, L, patch_size**2 *3)\n",
    "        \"\"\"\n",
    "        p = self.patch_embed.patch_size[0]\n",
    "        assert imgs.shape[2] == imgs.shape[3] and imgs.shape[2] % p == 0\n",
    "\n",
    "        h = w = imgs.shape[2] // p\n",
    "        x = imgs.reshape(shape=(imgs.shape[0], 8, h, p, w, p))\n",
    "        x = torch.einsum('nchpwq->nhwpqc', x)\n",
    "        x = x.reshape(shape=(imgs.shape[0], h * w, p**2 * 8))\n",
    "        return x\n",
    "\n",
    "    def unpatchify(self, x):\n",
    "        \"\"\"\n",
    "        x: (N, L, patch_size**2 *3)\n",
    "        imgs: (N, 8, H, W)\n",
    "        \"\"\"\n",
    "        p = self.patch_embed.patch_size[0]\n",
    "        h = w = int(x.shape[1]**.5)\n",
    "        assert h * w == x.shape[1]\n",
    "        \n",
    "        x = x.reshape(shape=(x.shape[0], h, w, p, p, 8))\n",
    "        x = torch.einsum('nhwpqc->nchpwq', x)\n",
    "        imgs = x.reshape(shape=(x.shape[0], 8, h * p, h * p))\n",
    "        return imgs\n",
    "\n",
    "    def forward(self, x, ids_restore):\n",
    "        # embed tokens\n",
    "        x = self.decoder_embed(x)\n",
    "\n",
    "        # append mask tokens to sequence\n",
    "        mask_tokens = self.mask_token.repeat(x.shape[0], ids_restore.shape[1] + 1 - x.shape[1], 1)\n",
    "        x_ = torch.cat([x[:, 1:, :], mask_tokens], dim=1)  # no cls token\n",
    "        x_ = torch.gather(x_, dim=1, index=ids_restore.unsqueeze(-1).repeat(1, 1, x.shape[2]))  # unshuffle\n",
    "        x = torch.cat([x[:, :1, :], x_], dim=1)  # append cls token\n",
    "\n",
    "        # add pos embed\n",
    "        x = x + self.decoder_pos_embed\n",
    "\n",
    "        # apply Transformer blocks\n",
    "        for blk in self.decoder_blocks:\n",
    "            x = blk(x)\n",
    "        x = self.decoder_norm(x)\n",
    "\n",
    "        # predictor projection\n",
    "        x = self.decoder_pred(x)\n",
    "\n",
    "        # remove cls token\n",
    "        x = x[:, 1:, :]\n",
    "\n",
    "        return x\n",
    "    \n",
    "class Masked_VIT(nn.Module):\n",
    "    def __init__(self, encoder, decoder, mask_ratio):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.mask_ratio = mask_ratio\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x, mask, ids_restore, imgs = self.encoder(x)\n",
    "        pred = self.decoder(x, ids_restore)\n",
    "        \n",
    "        return imgs, pred, mask\n",
    "    \n",
    "def mae_vit_base_patch16_dec512d8b(img_size=125, mask_ratio = 0.75, **kwargs):\n",
    "    encoder = Encoder(\n",
    "        img_size=img_size, patch_size=5, embed_dim=768, depth=8, num_heads=12,\n",
    "        decoder_embed_dim=512, decoder_depth=4, decoder_num_heads=16,\n",
    "        mlp_ratio=4, norm_layer=partial(nn.LayerNorm, eps=1e-6), **kwargs)\n",
    "    \n",
    "    decoder = Decoder(\n",
    "        img_size=img_size, patch_size=5, embed_dim=768, depth=8, num_heads=12,\n",
    "        decoder_embed_dim=512, decoder_depth=4, decoder_num_heads=16,\n",
    "        mlp_ratio=4, norm_layer=partial(nn.LayerNorm, eps=1e-6), **kwargs)\n",
    "    \n",
    "    model = Masked_VIT(encoder, decoder, mask_ratio)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Instantiate the model\n",
    "model = mae_vit_base_patch16_dec512d8b(img_size=125, mask_ratio = 0.75)\n",
    "# model = torch.load('/kaggle/input/pretrained-weights-autoencoder/model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40b4701e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T18:34:44.291800Z",
     "iopub.status.busy": "2024-03-18T18:34:44.291481Z",
     "iopub.status.idle": "2024-03-18T18:34:58.849735Z",
     "shell.execute_reply": "2024-03-18T18:34:58.848460Z"
    },
    "papermill": {
     "duration": 14.572388,
     "end_time": "2024-03-18T18:34:58.852568",
     "exception": false,
     "start_time": "2024-03-18T18:34:44.280180",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting einops\r\n",
      "  Downloading einops-0.7.0-py3-none-any.whl.metadata (13 kB)\r\n",
      "Downloading einops-0.7.0-py3-none-any.whl (44 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m648.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: einops\r\n",
      "Successfully installed einops-0.7.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac4848c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T18:34:58.879325Z",
     "iopub.status.busy": "2024-03-18T18:34:58.878298Z",
     "iopub.status.idle": "2024-03-18T18:34:58.883962Z",
     "shell.execute_reply": "2024-03-18T18:34:58.882899Z"
    },
    "papermill": {
     "duration": 0.021513,
     "end_time": "2024-03-18T18:34:58.886219",
     "exception": false,
     "start_time": "2024-03-18T18:34:58.864706",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.module.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8be828e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T18:34:58.911878Z",
     "iopub.status.busy": "2024-03-18T18:34:58.911451Z",
     "iopub.status.idle": "2024-03-18T18:34:58.943135Z",
     "shell.execute_reply": "2024-03-18T18:34:58.942170Z"
    },
    "papermill": {
     "duration": 0.047332,
     "end_time": "2024-03-18T18:34:58.945696",
     "exception": false,
     "start_time": "2024-03-18T18:34:58.898364",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from einops import repeat, rearrange\n",
    "from einops.layers.torch import Rearrange\n",
    "class VIT_classifier(nn.Module):\n",
    "    def __init__(self, encoder, num_classes):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.patch_embed = encoder.patch_embed\n",
    "        self.cls_token = encoder.cls_token\n",
    "        self.pos_embed = encoder.pos_embed  # Corrected attribute name\n",
    "        self.patchify = encoder.patchify\n",
    "        self.transformer = encoder.blocks  # Corrected attribute name\n",
    "        self.layer_norm = encoder.norm  # Corrected attribute name\n",
    "        self.head = torch.nn.Linear(self.pos_embed.shape[-1], num_classes)\n",
    "        self.blocks = encoder.blocks\n",
    "        \n",
    "        self.avg_pool = nn.AdaptiveAvgPool1d((1))\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(in_features=625, out_features=64)\n",
    "        self.fc_1 = nn.Linear(in_features=64, out_features=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.patch_embed(x)\n",
    "        \n",
    "        x = x + self.pos_embed[:, 1:, :]\n",
    "\n",
    "        # append cls token\n",
    "        cls_token = self.cls_token + self.pos_embed[:, :1, :]\n",
    "        cls_tokens = cls_token.expand(x.shape[0], -1, -1)\n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "\n",
    "        # apply Transformer blocks\n",
    "        for blk in self.blocks:\n",
    "            x = blk(x)\n",
    "        \n",
    "        x = self.layer_norm(x)\n",
    "        \n",
    "        x = x[:,1:,:]\n",
    "        x = self.avg_pool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        x = self.fc_1(x)\n",
    "        x = self.sigmoid(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "encoder = model.encoder\n",
    "classifier = VIT_classifier(encoder, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "770e0752",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T18:34:58.971516Z",
     "iopub.status.busy": "2024-03-18T18:34:58.970672Z",
     "iopub.status.idle": "2024-03-18T18:34:58.976152Z",
     "shell.execute_reply": "2024-03-18T18:34:58.975123Z"
    },
    "papermill": {
     "duration": 0.020706,
     "end_time": "2024-03-18T18:34:58.978526",
     "exception": false,
     "start_time": "2024-03-18T18:34:58.957820",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import torchvision\n",
    "# from torchview import draw_graph\n",
    "# from torchviz import make_dot\n",
    "\n",
    "# # # encoder = Encoder(\n",
    "# # #         img_size=125, patch_size=5, embed_dim=768, depth=8, num_heads=12,\n",
    "# # #         decoder_embed_dim=512, decoder_depth=4, decoder_num_heads=16,\n",
    "# # #         mlp_ratio=4, norm_layer=partial(nn.LayerNorm, eps=1e-6)\n",
    "# # # encoder = model.encoder\n",
    "\n",
    "# model_graph = draw_graph(classifier, input_size=(1,8,125,125), expand_nested=True)\n",
    "# model_graph.visual_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a23fa138",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T18:34:59.003756Z",
     "iopub.status.busy": "2024-03-18T18:34:59.003373Z",
     "iopub.status.idle": "2024-03-18T18:34:59.008034Z",
     "shell.execute_reply": "2024-03-18T18:34:59.006996Z"
    },
    "papermill": {
     "duration": 0.020148,
     "end_time": "2024-03-18T18:34:59.010671",
     "exception": false,
     "start_time": "2024-03-18T18:34:58.990523",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2c27472",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T18:34:59.035714Z",
     "iopub.status.busy": "2024-03-18T18:34:59.035382Z",
     "iopub.status.idle": "2024-03-18T18:35:20.644854Z",
     "shell.execute_reply": "2024-03-18T18:35:20.643868Z"
    },
    "papermill": {
     "duration": 21.624445,
     "end_time": "2024-03-18T18:35:20.647623",
     "exception": false,
     "start_time": "2024-03-18T18:34:59.023178",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for _z in range(8):\n",
    "    X[:,:,:,_z] = (X[:,:,:,_z] - X[:,:,:,_z].mean()) / (X[:,:,:,_z].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04f142a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T18:35:20.673320Z",
     "iopub.status.busy": "2024-03-18T18:35:20.672921Z",
     "iopub.status.idle": "2024-03-18T18:35:21.520305Z",
     "shell.execute_reply": "2024-03-18T18:35:21.518907Z"
    },
    "papermill": {
     "duration": 0.862797,
     "end_time": "2024-03-18T18:35:21.522627",
     "exception": false,
     "start_time": "2024-03-18T18:35:20.659830",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 125, 125])\n",
      "(1,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "class Custom_Dataset(Dataset):\n",
    "    def __init__(self, x, y, transform):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        img_1 = self.x[idx]\n",
    "        label = self.y[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            img_1 = self.transform(img_1)\n",
    "            \n",
    "        sample = {'img' : img_1, 'label' : label}\n",
    "        \n",
    "        return sample\n",
    "    \n",
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "\n",
    "dataset = Custom_Dataset(X, Y, transform = transform)\n",
    "sample = dataset.__getitem__(0)\n",
    "print((sample['img']).shape)\n",
    "print(sample['label'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97f1d480",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T18:35:21.550211Z",
     "iopub.status.busy": "2024-03-18T18:35:21.549287Z",
     "iopub.status.idle": "2024-03-18T18:35:21.554413Z",
     "shell.execute_reply": "2024-03-18T18:35:21.553409Z"
    },
    "papermill": {
     "duration": 0.020428,
     "end_time": "2024-03-18T18:35:21.556549",
     "exception": false,
     "start_time": "2024-03-18T18:35:21.536121",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70d91ca7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T18:35:21.581078Z",
     "iopub.status.busy": "2024-03-18T18:35:21.580759Z",
     "iopub.status.idle": "2024-03-18T18:35:25.201885Z",
     "shell.execute_reply": "2024-03-18T18:35:25.200856Z"
    },
    "papermill": {
     "duration": 3.636122,
     "end_time": "2024-03-18T18:35:25.204436",
     "exception": false,
     "start_time": "2024-03-18T18:35:21.568314",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "from torch import Tensor\n",
    "from typing import Type\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torchvision\n",
    "from torchview import draw_graph\n",
    "from torchviz import make_dot\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from torchmetrics import Accuracy\n",
    "import copy\n",
    "import torch.optim as optim\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "from torchmetrics import Accuracy\n",
    "from torch.utils.data import TensorDataset,random_split,SubsetRandomSampler, ConcatDataset\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.datasets import ImageFolder\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def model_train(fold, model, epochs, train_dataloader, test_dataloader):\n",
    "    \n",
    "    # --------------------Loss function and optimizer--------------------\n",
    "    criterion = nn.BCELoss()  # Binary Cross Entropy\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=1.5e-5)\n",
    "    # -------------------------------------------------------------------\n",
    "\n",
    "    best_acc = -np.inf  # Init to negative infinity\n",
    "    best_weights = None\n",
    "    accuracy = Accuracy(task = 'binary').to(DEVICE)\n",
    " \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_pred = []\n",
    "        val_pred = []\n",
    "        \n",
    "        # --------------------Training Loop--------------------\n",
    "        model.train()\n",
    "        for batch in tqdm(train_dataloader):\n",
    "            images, labels = batch['img'], batch['label']\n",
    "            images = images.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_pred.append(loss.item())\n",
    "\n",
    "            # Calculate training accuracy\n",
    "            train_acc = accuracy(outputs, labels)\n",
    "            train_accuracies.append(train_acc.item())\n",
    "\n",
    "        train_loss = np.mean(train_pred)\n",
    "        # -------------------------------------------------------\n",
    "        # -------------------------------------------------------\n",
    "        \n",
    "        # --------------------Validation Loop--------------------\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for val_batch in tqdm(test_dataloader):\n",
    "                val_images, val_labels = val_batch['img'], val_batch['label']\n",
    "                val_images = val_images.to(DEVICE)\n",
    "                val_labels = val_labels.to(DEVICE)\n",
    "\n",
    "                val_outputs = model(val_images)\n",
    "                val_loss = criterion(val_outputs, val_labels)\n",
    "                val_pred.append(val_loss.item())\n",
    "\n",
    "                # Calculate validation accuracy\n",
    "                val_acc = accuracy(val_outputs, val_labels)\n",
    "                val_accuracies.append(val_acc.item())\n",
    "\n",
    "        val_loss = np.mean(val_pred)\n",
    "        # -------------------------------------------------------\n",
    "        # -------------------------------------------------------\n",
    "        \n",
    "        # Print and store losses and accuracies\n",
    "        print(f'Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Train Accuracy: {np.mean(train_accuracies):.4f}, Valid Loss: {val_loss:.4f}, Valid Accuracy: {np.mean(val_accuracies):.4f}')\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        # Save best model\n",
    "        if max(train_accuracies) > best_acc:\n",
    "            best_acc = max(train_accuracies)\n",
    "            best_weights = copy.deepcopy(model.state_dict())\n",
    "    \n",
    "    # Save the best model\n",
    "    torch.save(best_weights, f'./best_model_{fold}.pth')\n",
    "\n",
    "    # Plot training and validation losses\n",
    "    return train_losses, val_losses, train_accuracies, val_accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6890976c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T18:35:25.230534Z",
     "iopub.status.busy": "2024-03-18T18:35:25.229936Z",
     "iopub.status.idle": "2024-03-18T18:35:25.463165Z",
     "shell.execute_reply": "2024-03-18T18:35:25.461987Z"
    },
    "papermill": {
     "duration": 0.249464,
     "end_time": "2024-03-18T18:35:25.466189",
     "exception": false,
     "start_time": "2024-03-18T18:35:25.216725",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "del classifier\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a1e8f3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T18:35:25.500005Z",
     "iopub.status.busy": "2024-03-18T18:35:25.499247Z",
     "iopub.status.idle": "2024-03-18T18:35:25.504439Z",
     "shell.execute_reply": "2024-03-18T18:35:25.503198Z"
    },
    "papermill": {
     "duration": 0.027003,
     "end_time": "2024-03-18T18:35:25.506824",
     "exception": false,
     "start_time": "2024-03-18T18:35:25.479821",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model = mae_vit_base_patch16_dec512d8b(img_size=125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a913e982",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T18:35:25.535435Z",
     "iopub.status.busy": "2024-03-18T18:35:25.535106Z",
     "iopub.status.idle": "2024-03-18T20:04:53.227627Z",
     "shell.execute_reply": "2024-03-18T20:04:53.226321Z"
    },
    "papermill": {
     "duration": 5367.710241,
     "end_time": "2024-03-18T20:04:53.230356",
     "exception": false,
     "start_time": "2024-03-18T18:35:25.520115",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [05:29<00:00,  2.64s/it]\n",
      "100%|██████████| 32/32 [00:26<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15, Train Loss: 0.6930, Train Accuracy: 0.5084, Valid Loss: 0.6919, Valid Accuracy: 0.5312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [05:32<00:00,  2.66s/it]\n",
      "100%|██████████| 32/32 [00:26<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/15, Train Loss: 0.6930, Train Accuracy: 0.5084, Valid Loss: 0.6919, Valid Accuracy: 0.5312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [05:30<00:00,  2.65s/it]\n",
      "100%|██████████| 32/32 [00:26<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/15, Train Loss: 0.6915, Train Accuracy: 0.5091, Valid Loss: 0.6856, Valid Accuracy: 0.5677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [05:30<00:00,  2.64s/it]\n",
      "100%|██████████| 32/32 [00:26<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/15, Train Loss: 0.6824, Train Accuracy: 0.5384, Valid Loss: 0.6722, Valid Accuracy: 0.5887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [05:31<00:00,  2.65s/it]\n",
      "100%|██████████| 32/32 [00:26<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/15, Train Loss: 0.6652, Train Accuracy: 0.5600, Valid Loss: 0.6498, Valid Accuracy: 0.6047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [05:32<00:00,  2.66s/it]\n",
      "100%|██████████| 32/32 [00:26<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/15, Train Loss: 0.6335, Train Accuracy: 0.5812, Valid Loss: 0.6285, Valid Accuracy: 0.6176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [05:31<00:00,  2.65s/it]\n",
      "100%|██████████| 32/32 [00:26<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/15, Train Loss: 0.6173, Train Accuracy: 0.5973, Valid Loss: 0.6082, Valid Accuracy: 0.6295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [05:31<00:00,  2.65s/it]\n",
      "100%|██████████| 32/32 [00:26<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/15, Train Loss: 0.6127, Train Accuracy: 0.6088, Valid Loss: 0.5938, Valid Accuracy: 0.6400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [05:31<00:00,  2.66s/it]\n",
      "100%|██████████| 32/32 [00:26<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/15, Train Loss: 0.5774, Train Accuracy: 0.6220, Valid Loss: 0.5486, Valid Accuracy: 0.6522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [05:31<00:00,  2.66s/it]\n",
      "100%|██████████| 32/32 [00:26<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/15, Train Loss: 0.5352, Train Accuracy: 0.6362, Valid Loss: 0.5218, Valid Accuracy: 0.6635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [05:31<00:00,  2.66s/it]\n",
      "100%|██████████| 32/32 [00:26<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/15, Train Loss: 0.5161, Train Accuracy: 0.6479, Valid Loss: 0.5728, Valid Accuracy: 0.6695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [05:30<00:00,  2.65s/it]\n",
      "100%|██████████| 32/32 [00:26<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/15, Train Loss: 0.5093, Train Accuracy: 0.6580, Valid Loss: 0.4864, Valid Accuracy: 0.6794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [05:30<00:00,  2.65s/it]\n",
      "100%|██████████| 32/32 [00:26<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/15, Train Loss: 0.4954, Train Accuracy: 0.6672, Valid Loss: 0.4882, Valid Accuracy: 0.6867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [05:31<00:00,  2.65s/it]\n",
      "100%|██████████| 32/32 [00:26<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/15, Train Loss: 0.4767, Train Accuracy: 0.6758, Valid Loss: 0.5227, Valid Accuracy: 0.6919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [05:31<00:00,  2.66s/it]\n",
      "100%|██████████| 32/32 [00:26<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/15, Train Loss: 0.5238, Train Accuracy: 0.6813, Valid Loss: 0.5265, Valid Accuracy: 0.6951\n"
     ]
    }
   ],
   "source": [
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "training_loss = []\n",
    "validation_loss = []\n",
    "# Create data loaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "classifier = VIT_classifier(model.encoder, 2)\n",
    "NUM_GPU = torch.cuda.device_count()\n",
    "if NUM_GPU > 1:\n",
    "    classifier = nn.DataParallel(classifier)\n",
    "classifier = classifier.to(DEVICE)\n",
    "\n",
    "train_losses, val_losses, train_accuracies, val_accuracies = model_train(1,classifier, 15, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4b78041",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T20:04:53.670340Z",
     "iopub.status.busy": "2024-03-18T20:04:53.669959Z",
     "iopub.status.idle": "2024-03-18T20:04:53.674862Z",
     "shell.execute_reply": "2024-03-18T20:04:53.673628Z"
    },
    "papermill": {
     "duration": 0.224912,
     "end_time": "2024-03-18T20:04:53.677203",
     "exception": false,
     "start_time": "2024-03-18T20:04:53.452291",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# torch.save(model, f'./best_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "492b8998",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T20:04:54.109047Z",
     "iopub.status.busy": "2024-03-18T20:04:54.108177Z",
     "iopub.status.idle": "2024-03-18T20:04:54.112707Z",
     "shell.execute_reply": "2024-03-18T20:04:54.111861Z"
    },
    "papermill": {
     "duration": 0.224331,
     "end_time": "2024-03-18T20:04:54.114655",
     "exception": false,
     "start_time": "2024-03-18T20:04:53.890324",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoder = classifier.module.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1bc6a68c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T20:04:54.555254Z",
     "iopub.status.busy": "2024-03-18T20:04:54.554856Z",
     "iopub.status.idle": "2024-03-18T20:04:54.898892Z",
     "shell.execute_reply": "2024-03-18T20:04:54.898034Z"
    },
    "papermill": {
     "duration": 0.569385,
     "end_time": "2024-03-18T20:04:54.901326",
     "exception": false,
     "start_time": "2024-03-18T20:04:54.331941",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(encoder, 'encoder.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d110155",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T20:04:55.379217Z",
     "iopub.status.busy": "2024-03-18T20:04:55.378536Z",
     "iopub.status.idle": "2024-03-18T20:04:55.747051Z",
     "shell.execute_reply": "2024-03-18T20:04:55.746141Z"
    },
    "papermill": {
     "duration": 0.609555,
     "end_time": "2024-03-18T20:04:55.749692",
     "exception": false,
     "start_time": "2024-03-18T20:04:55.140137",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(classifier.module, 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c4302097",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T20:04:56.204610Z",
     "iopub.status.busy": "2024-03-18T20:04:56.203932Z",
     "iopub.status.idle": "2024-03-18T20:04:56.530763Z",
     "shell.execute_reply": "2024-03-18T20:04:56.529815Z"
    },
    "papermill": {
     "duration": 0.562162,
     "end_time": "2024-03-18T20:04:56.532964",
     "exception": false,
     "start_time": "2024-03-18T20:04:55.970802",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f74ef6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T20:04:56.981084Z",
     "iopub.status.busy": "2024-03-18T20:04:56.980688Z",
     "iopub.status.idle": "2024-03-18T20:04:56.993095Z",
     "shell.execute_reply": "2024-03-18T20:04:56.992102Z"
    },
    "papermill": {
     "duration": 0.236485,
     "end_time": "2024-03-18T20:04:56.994981",
     "exception": false,
     "start_time": "2024-03-18T20:04:56.758496",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class MaskedAutoencoderViT(nn.Module):\n",
    "#     \"\"\" Masked Autoencoder with VisionTransformer backbone\n",
    "#     \"\"\"\n",
    "#     def __init__(self, img_size=224, patch_size=16, in_chans=8,\n",
    "#                  embed_dim=1024, depth=24, num_heads=16,\n",
    "#                  decoder_embed_dim=512, decoder_depth=8, decoder_num_heads=16,\n",
    "#                  mlp_ratio=4., norm_layer=nn.LayerNorm, norm_pix_loss=False):\n",
    "#         super().__init__()\n",
    "\n",
    "#         # --------------------------------------------------------------------------\n",
    "#         # MAE encoder specifics\n",
    "#         self.patch_embed = PatchEmbed(img_size, patch_size, in_chans, embed_dim)\n",
    "#         num_patches = self.patch_embed.num_patches\n",
    "\n",
    "#         self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
    "#         self.pos_embed = nn.Parameter(torch.zeros(1, num_patches + 1, embed_dim), requires_grad=False)  # fixed sin-cos embedding\n",
    "\n",
    "#         self.blocks = nn.ModuleList([\n",
    "#             Block(embed_dim, num_heads, mlp_ratio, qkv_bias=True, norm_layer=norm_layer)\n",
    "#             for i in range(depth)])\n",
    "#         self.norm = norm_layer(embed_dim)\n",
    "#         # --------------------------------------------------------------------------\n",
    "\n",
    "#         # --------------------------------------------------------------------------\n",
    "#         # MAE decoder specifics\n",
    "#         self.decoder_embed = nn.Linear(embed_dim, decoder_embed_dim, bias=True)\n",
    "\n",
    "#         self.mask_token = nn.Parameter(torch.zeros(1, 1, decoder_embed_dim))\n",
    "\n",
    "#         self.decoder_pos_embed = nn.Parameter(torch.zeros(1, num_patches + 1, decoder_embed_dim), requires_grad=False)  # fixed sin-cos embedding\n",
    "\n",
    "#         self.decoder_blocks = nn.ModuleList([\n",
    "#             Block(decoder_embed_dim, decoder_num_heads, mlp_ratio, qkv_bias=True, norm_layer=norm_layer)\n",
    "#             for i in range(decoder_depth)])\n",
    "\n",
    "#         self.decoder_norm = norm_layer(decoder_embed_dim)\n",
    "#         self.decoder_pred = nn.Linear(decoder_embed_dim, patch_size**2 * in_chans, bias=True) # decoder to patch\n",
    "#         # --------------------------------------------------------------------------\n",
    "\n",
    "#         self.norm_pix_loss = norm_pix_loss\n",
    "\n",
    "#         self.initialize_weights()\n",
    "\n",
    "#     def initialize_weights(self):\n",
    "#         # initialization\n",
    "#         # initialize (and freeze) pos_embed by sin-cos embedding\n",
    "#         pos_embed = get_2d_sincos_pos_embed(self.pos_embed.shape[-1], int(self.patch_embed.num_patches**.5), cls_token=True)\n",
    "#         self.pos_embed.data.copy_(torch.from_numpy(pos_embed).float().unsqueeze(0))\n",
    "\n",
    "#         decoder_pos_embed = get_2d_sincos_pos_embed(self.decoder_pos_embed.shape[-1], int(self.patch_embed.num_patches**.5), cls_token=True)\n",
    "#         self.decoder_pos_embed.data.copy_(torch.from_numpy(decoder_pos_embed).float().unsqueeze(0))\n",
    "\n",
    "#         # initialize patch_embed like nn.Linear (instead of nn.Conv2d)\n",
    "#         w = self.patch_embed.proj.weight.data\n",
    "#         torch.nn.init.xavier_uniform_(w.view([w.shape[0], -1]))\n",
    "\n",
    "#         # timm's trunc_normal_(std=.02) is effectively normal_(std=0.02) as cutoff is too big (2.)\n",
    "#         torch.nn.init.normal_(self.cls_token, std=.02)\n",
    "#         torch.nn.init.normal_(self.mask_token, std=.02)\n",
    "\n",
    "#         # initialize nn.Linear and nn.LayerNorm\n",
    "#         self.apply(self._init_weights)\n",
    "\n",
    "#     def _init_weights(self, m):\n",
    "#         if isinstance(m, nn.Linear):\n",
    "#             # we use xavier_uniform following official JAX ViT:\n",
    "#             torch.nn.init.xavier_uniform_(m.weight)\n",
    "#             if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "#                 nn.init.constant_(m.bias, 0)\n",
    "#         elif isinstance(m, nn.LayerNorm):\n",
    "#             nn.init.constant_(m.bias, 0)\n",
    "#             nn.init.constant_(m.weight, 1.0)\n",
    "\n",
    "#     def patchify(self, imgs):\n",
    "#         \"\"\"\n",
    "#         imgs: (N, 8, H, W)\n",
    "#         x: (N, L, patch_size**2 *3)\n",
    "#         \"\"\"\n",
    "#         p = self.patch_embed.patch_size[0]\n",
    "#         assert imgs.shape[2] == imgs.shape[3] and imgs.shape[2] % p == 0\n",
    "\n",
    "#         h = w = imgs.shape[2] // p\n",
    "#         x = imgs.reshape(shape=(imgs.shape[0], 8, h, p, w, p))\n",
    "#         x = torch.einsum('nchpwq->nhwpqc', x)\n",
    "#         x = x.reshape(shape=(imgs.shape[0], h * w, p**2 * 8))\n",
    "#         return x\n",
    "\n",
    "#     def unpatchify(self, x):\n",
    "#         \"\"\"\n",
    "#         x: (N, L, patch_size**2 *3)\n",
    "#         imgs: (N, 8, H, W)\n",
    "#         \"\"\"\n",
    "#         p = self.patch_embed.patch_size[0]\n",
    "#         h = w = int(x.shape[1]**.5)\n",
    "#         assert h * w == x.shape[1]\n",
    "        \n",
    "#         x = x.reshape(shape=(x.shape[0], h, w, p, p, 8))\n",
    "#         x = torch.einsum('nhwpqc->nchpwq', x)\n",
    "#         imgs = x.reshape(shape=(x.shape[0], 8, h * p, h * p))\n",
    "#         return imgs\n",
    "\n",
    "#     def random_masking(self, x, mask_ratio):\n",
    "#         \"\"\"\n",
    "#         Perform per-sample random masking by per-sample shuffling.\n",
    "#         Per-sample shuffling is done by argsort random noise.\n",
    "#         x: [N, L, D], sequence\n",
    "#         \"\"\"\n",
    "#         N, L, D = x.shape  # batch, length, dim\n",
    "#         len_keep = int(L * (1 - mask_ratio))\n",
    "        \n",
    "#         noise = torch.rand(N, L, device=x.device)  # noise in [0, 1]\n",
    "        \n",
    "#         # sort noise for each sample\n",
    "#         ids_shuffle = torch.argsort(noise, dim=1)  # ascend: small is keep, large is remove\n",
    "#         ids_restore = torch.argsort(ids_shuffle, dim=1)\n",
    "\n",
    "#         # keep the first subset\n",
    "#         ids_keep = ids_shuffle[:, :len_keep]\n",
    "#         x_masked = torch.gather(x, dim=1, index=ids_keep.unsqueeze(-1).repeat(1, 1, D))\n",
    "\n",
    "#         # generate the binary mask: 0 is keep, 1 is remove\n",
    "#         mask = torch.ones([N, L], device=x.device)\n",
    "#         mask[:, :len_keep] = 0\n",
    "#         # unshuffle to get the binary mask\n",
    "#         mask = torch.gather(mask, dim=1, index=ids_restore)\n",
    "\n",
    "#         return x_masked, mask, ids_restore\n",
    "\n",
    "#     def forward_encoder(self, x, mask_ratio):\n",
    "#         # embed patches\n",
    "#         x = self.patch_embed(x)\n",
    "\n",
    "#         # add pos embed w/o cls token\n",
    "#         x = x + self.pos_embed[:, 1:, :]\n",
    "\n",
    "#         # masking: length -> length * mask_ratio\n",
    "#         x, mask, ids_restore = self.random_masking(x, mask_ratio)\n",
    "\n",
    "#         # append cls token\n",
    "#         cls_token = self.cls_token + self.pos_embed[:, :1, :]\n",
    "#         cls_tokens = cls_token.expand(x.shape[0], -1, -1)\n",
    "#         x = torch.cat((cls_tokens, x), dim=1)\n",
    "\n",
    "#         # apply Transformer blocks\n",
    "#         for blk in self.blocks:\n",
    "#             x = blk(x)\n",
    "#         x = self.norm(x)\n",
    "\n",
    "#         return x, mask, ids_restore\n",
    "\n",
    "#     def forward_decoder(self, x, ids_restore):\n",
    "#         # embed tokens\n",
    "#         x = self.decoder_embed(x)\n",
    "\n",
    "#         # append mask tokens to sequence\n",
    "#         mask_tokens = self.mask_token.repeat(x.shape[0], ids_restore.shape[1] + 1 - x.shape[1], 1)\n",
    "#         x_ = torch.cat([x[:, 1:, :], mask_tokens], dim=1)  # no cls token\n",
    "#         x_ = torch.gather(x_, dim=1, index=ids_restore.unsqueeze(-1).repeat(1, 1, x.shape[2]))  # unshuffle\n",
    "#         x = torch.cat([x[:, :1, :], x_], dim=1)  # append cls token\n",
    "\n",
    "#         # add pos embed\n",
    "#         x = x + self.decoder_pos_embed\n",
    "\n",
    "#         # apply Transformer blocks\n",
    "#         for blk in self.decoder_blocks:\n",
    "#             x = blk(x)\n",
    "#         x = self.decoder_norm(x)\n",
    "\n",
    "#         # predictor projection\n",
    "#         x = self.decoder_pred(x)\n",
    "\n",
    "#         # remove cls token\n",
    "#         x = x[:, 1:, :]\n",
    "\n",
    "#         return x\n",
    "\n",
    "#     def forward(self, imgs, mask_ratio=0.75):\n",
    "#         latent, mask, ids_restore = self.forward_encoder(imgs, mask_ratio)\n",
    "#         pred = self.forward_decoder(latent, ids_restore)  # [N, L, p*p*3]\n",
    "# #         loss = self.forward_loss(imgs, pred, mask)\n",
    "#         imgs = self.patchify(imgs)\n",
    "#         return imgs, pred, mask\n",
    "\n",
    "\n",
    "# # def mae_vit_base_patch16_dec512d8b(**kwargs):\n",
    "# #     model = MaskedAutoencoderViT(\n",
    "# #         img_size=125,patch_size=5, embed_dim=768, depth=12, num_heads=12,\n",
    "# #         decoder_embed_dim=512, decoder_depth=8, decoder_num_heads=16,\n",
    "# #         mlp_ratio=4, norm_layer=partial(nn.LayerNorm, eps=1e-6), **kwargs)\n",
    "# #     return model\n",
    "\n",
    "\n",
    "# # # set recommended archs\n",
    "# # model = mae_vit_base_patch16_dec512d8b (img_size = 125) # decoder: 512 dim, 8 blocks\n",
    "# def mae_vit_base_patch16_dec512d8b(img_size=125, **kwargs):\n",
    "#     model = MaskedAutoencoderViT(\n",
    "#         img_size=img_size, patch_size=5, embed_dim=768, depth=8, num_heads=12,\n",
    "#         decoder_embed_dim=512, decoder_depth=4, decoder_num_heads=16,\n",
    "#         mlp_ratio=4, norm_layer=partial(nn.LayerNorm, eps=1e-6), **kwargs)\n",
    "#     return model\n",
    "\n",
    "# # Instantiate the model\n",
    "# model = mae_vit_base_patch16_dec512d8b(img_size=125)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4495984,
     "sourceId": 7701936,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4605304,
     "sourceId": 7852519,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30665,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5501.229971,
   "end_time": "2024-03-18T20:05:00.566166",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-18T18:33:19.336195",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
