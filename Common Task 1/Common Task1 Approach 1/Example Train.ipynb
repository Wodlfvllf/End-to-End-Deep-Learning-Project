{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbb6665e-7cc4-4a17-a5af-5383de60bf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_c1 import *\n",
    "from Model_c1 import *\n",
    "from dataset_c1 import *\n",
    "from train_c1 import *\n",
    "from predict_c1 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e423f67a-8ad4-42f6-9158-d4ee911c151d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -------------------------------------------------------\n",
    "#                   Electron Images\n",
    "# -------------------------------------------------------\n",
    "filename = \"/DATA/Shashank/SingleElectronPt50_IMGCROPS_n249k_RHv1.hdf5\"\n",
    "hf = h5py.File(filename, 'r')\n",
    "X_Electron = np.array(hf[\"X\"][:])\n",
    "Y_Electron = np.array(hf[\"y\"][:])\n",
    "Y_Electron[0]\n",
    "\n",
    "# -------------------------------------------------------\n",
    "#                   Photon Images\n",
    "# -------------------------------------------------------\n",
    "filename1 = '/DATA/Shashank/SinglePhotonPt50_IMGCROPS_n249k_RHv1.hdf5'\n",
    "h = h5py.File(filename1, 'r')\n",
    "X_Photon = np.array(h[\"X\"][:])\n",
    "Y_Photon = np.array(h[\"y\"][:])\n",
    "Y_Photon[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16010baa-2093-4e88-a12c-8c16db4216ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(498000,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.concatenate((X_Electron, X_Photon), axis = 0)\n",
    "X_train.shape\n",
    "\n",
    "Y_train = np.concatenate((Y_Electron, Y_Photon))\n",
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99518725-80e1-49d2-9a78-32cbf51b49b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming X_train and Y_train are your data and labels arrays\n",
    "combined = list(zip(X_train, Y_train))\n",
    "np.random.shuffle(combined)\n",
    "X_train_shuffled, Y_train_shuffled = zip(*combined)\n",
    "\n",
    "# Convert back to numpy arrays if necessary\n",
    "X_train_shuffled = np.array(X_train_shuffled)\n",
    "Y_train_shuffled = np.array(Y_train_shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ef91117-5292-4521-9a86-dcbffdc22bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "dataset = CustomDataset(X_train_shuffled, Y_train_shuffled, transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ca95f4-e945-4e25-b1bc-e0bfd403f724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Fold 0***\n",
      "Training Started.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 1/1 [03:27<00:00, 207.70s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Train Loss: 0.5966, Train Accuracy: 0.6908, Valid Loss: 0.6199, Valid Accuracy: 0.6732\n",
      "*** Fold 1***\n",
      "Training Started.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epochs: 100%|██████████| 1/1 [03:27<00:00, 207.71s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Train Loss: 0.5981, Train Accuracy: 0.6914, Valid Loss: 0.8125, Valid Accuracy: 0.6030\n",
      "*** Fold 2***\n",
      "Training Started.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epochs: 100%|██████████| 1/1 [03:23<00:00, 203.76s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Train Loss: 0.5959, Train Accuracy: 0.6891, Valid Loss: 0.5670, Valid Accuracy: 0.7154\n",
      "*** Fold 3***\n",
      "Training Started.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epochs: 100%|██████████| 1/1 [03:39<00:00, 219.93s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Train Loss: 0.5966, Train Accuracy: 0.6917, Valid Loss: 0.6199, Valid Accuracy: 0.6772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Fold 4***\n",
      "Training Started.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|          | 0/1 [00:00<?, ?epoch/s]"
     ]
    }
   ],
   "source": [
    "# import timm\n",
    "from torch.utils.data import Dataset, DataLoader,TensorDataset,random_split,SubsetRandomSampler, ConcatDataset\n",
    "from sklearn.model_selection import KFold\n",
    "k_folds = 5\n",
    "batch_size = 256\n",
    "kf = KFold(n_splits=k_folds, shuffle=True)\n",
    "trn_fold_loss = []\n",
    "val_fold_loss = []\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(dataset)):\n",
    "    \n",
    "    print(f'*** Fold {fold}***')\n",
    "    print('Training Started.....')\n",
    "    train_loader = DataLoader(dataset=dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              sampler=torch.utils.data.SubsetRandomSampler(train_idx),\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(dataset=dataset,\n",
    "                             batch_size=batch_size,\n",
    "                             sampler=torch.utils.data.SubsetRandomSampler(test_idx),\n",
    "    )\n",
    "    \n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "    model = Resnet_Ensemble(2, 15, BasicBlock, CBAM, resnet = ResNet)\n",
    "    NUM_GPU = torch.cuda.device_count()\n",
    "    if NUM_GPU > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "    model = model.to(DEVICE)\n",
    "\n",
    "    trainer = Trainer(fold, model, train_dataloader = train_loader, test_dataloader = test_loader)\n",
    "    trn_loss, val_loss, trn_acc, val_acc = trainer.model_train(fold = fold, epochs = 1)\n",
    "    trn_fold_loss.append(trn_loss)\n",
    "    val_fold_loss.append(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e63204-cf10-46cb-a791-758c8f276109",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(k_folds):\n",
    "    plt.plot(trn_fold_loss[i], label='Training Loss')\n",
    "    plt.plot(val_fold_loss[i], label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24c5d54-6747-4284-8635-13bf98b9751f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
